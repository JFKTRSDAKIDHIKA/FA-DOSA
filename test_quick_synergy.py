"""
å¿«é€Ÿæµ‹è¯•æ–°çš„ååŒä¼˜åŒ–åŠŸèƒ½ä¸å®éªŒæ¡†æ¶çš„å…¼å®¹æ€§
"""
import torch
import torch.optim as optim
import time

from fa_dosa_demo import (
    HardwareParameters,
    MappingParameters,
    FusionParameters,
    Config,
    ComputationGraph,
    ConditionalPerformanceModel,
    calculate_total_loss_with_hardware_constraints,
    create_example_optimization_setup,
)
from onnx_frontend import parse_onnx_to_graph


def quick_synergy_test():
    """å¿«é€Ÿæµ‹è¯•ååŒä¼˜åŒ–åŠŸèƒ½"""
    print("ğŸš€ å¿«é€ŸååŒä¼˜åŒ–å…¼å®¹æ€§æµ‹è¯•...")
    
    # åŠ è½½é…ç½®
    config = Config.get_instance()
    
    # ä½¿ç”¨ç°æœ‰çš„ONNXæ–‡ä»¶
    try:
        graph = parse_onnx_to_graph('simple_cnn.onnx')
        print(f"  âœ“ åŠ è½½å›¾æˆåŠŸ: {len(graph.layers)} å±‚, {len(graph.fusion_groups)} ä¸ªèåˆç»„")
    except FileNotFoundError:
        print("  âœ— æœªæ‰¾åˆ° simple_cnn.onnx")
        return
    
    # ä½¿ç”¨æ ‡å‡†çš„è®¾ç½®å‡½æ•°
    mapping_params, fusion_params, hardware_params = create_example_optimization_setup(graph)
    performance_model = ConditionalPerformanceModel()
    
    print("  ğŸ“Š åˆå§‹è¯„ä¼°...")
    with torch.no_grad():
        initial_latency, initial_energy, initial_area = performance_model(
            mapping_params, fusion_params, hardware_params, graph
        )
        print(f"    åˆå§‹ EDP: {(initial_latency * initial_energy).item():.4e}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆæ¨¡æ‹Ÿå®éªŒè„šæœ¬ä¸­çš„è®¾ç½®ï¼‰
    optimizer = optim.Adam(
        list(mapping_params.parameters()) + 
        list(fusion_params.parameters()) + 
        list(hardware_params.parameters()), 
        lr=1e-3
    )
    
    print("  ğŸ”„ å¼€å§‹ä¼˜åŒ–ï¼ˆ50è½®ï¼‰...")
    start_time = time.time()
    
    for i in range(50):
        optimizer.zero_grad()
        total_loss = calculate_total_loss_with_hardware_constraints(
            performance_model, mapping_params, fusion_params, hardware_params, graph
        )
        total_loss.backward()
        optimizer.step()
        
        if i % 10 == 0:
            print(f"    è½®æ¬¡ {i}: æŸå¤± = {total_loss.item():.4f}")
    
    elapsed = time.time() - start_time
    print(f"  â±ï¸  ä¼˜åŒ–å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}s")
    
    # æœ€ç»ˆè¯„ä¼°
    with torch.no_grad():
        final_latency, final_energy, final_area = performance_model(
            mapping_params, fusion_params, hardware_params, graph
        )
        final_edp = final_latency * final_energy
        print(f"    æœ€ç»ˆ EDP: {final_edp.item():.4e}")
        
        improvement = (initial_latency * initial_energy - final_edp) / (initial_latency * initial_energy) * 100
        print(f"    æ€§èƒ½æå‡: {improvement.item():.2f}%")
    
    # æ£€æŸ¥èåˆå†³ç­–
    print("  ğŸ”€ æœ€ç»ˆèåˆå†³ç­–:")
    for sanitized_key, prob_tensor in fusion_params.fusion_probs.items():
        prob_value = torch.sigmoid(prob_tensor).item()
        decision = "FUSE" if prob_value > 0.5 else "NO_FUSE"
        print(f"    {sanitized_key}: {prob_value:.3f} â†’ {decision}")
    
    print("  âœ… å…¼å®¹æ€§æµ‹è¯•å®Œæˆ!")
    
    return {
        'initial_edp': (initial_latency * initial_energy).item(),
        'final_edp': final_edp.item(),
        'improvement_percent': improvement.item(),
        'execution_time': elapsed
    }


if __name__ == "__main__":
    results = quick_synergy_test()
    if results:
        print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœ:")
        print(f"  åˆå§‹ EDP: {results['initial_edp']:.4e}")
        print(f"  æœ€ç»ˆ EDP: {results['final_edp']:.4e}")
        print(f"  æ€§èƒ½æå‡: {results['improvement_percent']:.2f}%")
        print(f"  æ‰§è¡Œæ—¶é—´: {results['execution_time']:.2f}s") 